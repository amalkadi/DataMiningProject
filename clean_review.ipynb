{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import csv\n",
    "import numpy as np\n",
    "import unicodedata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2225213\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# filter useful info from review.json to output/reviews.csv\n",
    "################################################################################\n",
    "columns = ['Id', 'UserId', 'Stars', 'Date', 'BusinessId'] #create required columns \n",
    "question_dataframe_file = open('./output/reviews.csv', 'wb')\n",
    "writer = csv.writer(question_dataframe_file, delimiter=',')\n",
    "writer.writerow(columns)\n",
    "c = 0\n",
    "with open('./yelp_dataset/yelp_academic_dataset_review.json') as data_file:\n",
    "    for line in data_file:\n",
    "        c+=1\n",
    "        review = json.loads(line)\n",
    "        writer.writerow([review['review_id'], review['user_id'], review['stars'], review['date'], review['business_id'] ] )\n",
    "        if c%100000==0:\n",
    "            print c\n",
    "print c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77445\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# flatten dict keys in business.csv\n",
    "########################################\n",
    "c = 0\n",
    "cols = []\n",
    "with open('./yelp_dataset/yelp_academic_dataset_business.json') as data_file:\n",
    "    for line in data_file:           \n",
    "        c+=1\n",
    "        review = json.loads(line)\n",
    "        #print review\n",
    "        for catg in review:\n",
    "            if type(review[catg]) is dict:\n",
    "                for item in review[catg]:\n",
    "                    if type(review[catg][item]) is dict:\n",
    "                        for nesteditem in review[catg][item]:\n",
    "                            toappend = catg+\":\"+item+\":\"+nesteditem\n",
    "                            if toappend not in cols:\n",
    "                                cols.append(toappend)\n",
    "                                #print toappend\n",
    "                    else:\n",
    "                        toappend = catg+\":\"+item\n",
    "                        if toappend not in cols:\n",
    "                            cols.append(toappend)\n",
    "                            #print toappend\n",
    "            elif catg not in cols:\n",
    "                cols.append(catg)\n",
    "                #print catg\n",
    "#         pprint.pprint(review)\n",
    "#         if c%100000==0:\n",
    "        #print c\n",
    "#         break\n",
    "print c\n",
    "print len(cols)\n",
    "cols.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "77445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nERROR parsing to ascii code: 72\\nERROR parsing to ascii code: 89\\nERROR parsing to ascii code: 90\\nERROR parsing to ascii code: 92\\nERROR parsing to ascii code: 93\\nERROR parsing to ascii code: 94\\nERROR parsing to ascii code: 95\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "# write attributes to business.csv file\n",
    "########################################\n",
    "business_dataframe = open('./output/business.csv', 'wb')\n",
    "writer = csv.writer(business_dataframe, delimiter=',')\n",
    "writer.writerow(cols)\n",
    "with open('./yelp_dataset/yelp_academic_dataset_business.json') as data_file:\n",
    "    c=0\n",
    "    for line in data_file:           \n",
    "        c+=1\n",
    "        a = ['N/A'] * 98 #create an array of None by default\n",
    "        business = json.loads(line)\n",
    "        for i in range (len(a) - 1):\n",
    "            level = cols[i].split(':')\n",
    "            if len(level) == 1:\n",
    "                a[i] = business[cols[i]]\n",
    "                try:\n",
    "                    nfkd_form = unicodedata.normalize('NFKD', a[i])\n",
    "                    a[i] = nfkd_form.encode('ASCII', 'ignore')\n",
    "                except:\n",
    "#                     print 'ERROR parsing to ascii code:', i\n",
    "                    pass\n",
    "            elif len(level) == 2:\n",
    "                if level[1] in business[level[0]].keys():\n",
    "                    a[i] = business[level[0]][level[1]]\n",
    "            elif len(level) == 3:\n",
    "                if level[1] in business[level[0]].keys():\n",
    "                    if level[2] in business[level[0]][level[1]].keys():\n",
    "                        a[i] =  business[level[0]][level[1]][level[2]]\n",
    "            # remove '\\n' in address\n",
    "            if cols[i] == 'full_address':\n",
    "                a[i] = a[i].replace('\\n', '')\n",
    "        writer.writerow(a)\n",
    "        if c % 1000 == 0:\n",
    "            print c\n",
    "\n",
    "print c\n",
    "business_dataframe.close()\n",
    "\n",
    "'''\n",
    "ERROR parsing to ascii code: 72\n",
    "ERROR parsing to ascii code: 89\n",
    "ERROR parsing to ascii code: 90\n",
    "ERROR parsing to ascii code: 92\n",
    "ERROR parsing to ascii code: 93\n",
    "ERROR parsing to ascii code: 94\n",
    "ERROR parsing to ascii code: 95\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ne.g.\\n>>> flatten({'a': 1, 'c': {'a': 2, 'b': {'x': 5, 'y' : 10}}, 'd': [1, 2, 3]})\\n{'a': 1, 'c_a': 2, 'c_b_x': 5, 'd': [1, 2, 3], 'c_b_y': 10}\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "# flatten dict reference, function not used\n",
    "########################################\n",
    "'''\n",
    "import collections\n",
    "\n",
    "def flatten(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            #recursive call\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "'''\n",
    "\n",
    "'''\n",
    "e.g.\n",
    ">>> flatten({'a': 1, 'c': {'a': 2, 'b': {'x': 5, 'y' : 10}}, 'd': [1, 2, 3]})\n",
    "{'a': 1, 'c_a': 2, 'c_b_x': 5, 'd': [1, 2, 3], 'c_b_y': 10}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55569\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# filter checkin.json to checkin.csv\n",
    "########################################\n",
    "columns = ['BusinessId', '0-1', '1-2', '2-3', '3-4', '4-5', '5-6', '6-7', '7-8', '8-9', '9-10',\n",
    "          '10-11', '11-12', '12-13', '13-14', '14-15', '15-16', '16-17', '17-18', '18-19','19-20', '20-21','21-22',\n",
    "          '22-23', '23-0'] #create required columns \n",
    "question_dataframe_file = open('./output/checkin.csv', 'wb')\n",
    "writer = csv.writer(question_dataframe_file, delimiter=',')\n",
    "writer.writerow(columns)\n",
    "c = 0\n",
    "with open('./yelp_dataset/yelp_academic_dataset_checkin.json') as data_file:\n",
    "    for line in data_file:\n",
    "        times = np.zeros(24)\n",
    "        c+=1\n",
    "        review = json.loads(line)\n",
    "        keys = review['checkin_info'].keys()\n",
    "        #print keys\n",
    "        for key in keys:\n",
    "            #print hours\n",
    "            #print key\n",
    "            #print review['checkin_info'][key]\n",
    "            hours = int(key.split('-')[0])\n",
    "            times[hours] += review['checkin_info'][key]\n",
    "            \n",
    "         \n",
    "        writer.writerow([review['business_id'], times[0], times[1], times[2], times[3], times[4], times[5],\n",
    "                         times[6], times[7], times[8], times[9], times[10], times[11], times[12], times[13], times[14],\n",
    "                          times[15], times[16],  times[17], times[18], times[19], times[20], times[21], times[22], times[23]])\n",
    "\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55569\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# filter checkin.json to checkin.csv (percentage version)\n",
    "################################################################################\n",
    "columns = ['BusinessId', 'total', '0-1', '1-2', '2-3', '3-4', '4-5', '5-6', '6-7', '7-8', '8-9', '9-10',\n",
    "          '10-11', '11-12', '12-13', '13-14', '14-15', '15-16', '16-17', '17-18', '18-19','19-20', '20-21','21-22',\n",
    "          '22-23', '23-0'] #create required columns \n",
    "question_dataframe_file = open('./output/checkin total.csv', 'wb')\n",
    "writer = csv.writer(question_dataframe_file, delimiter=',')\n",
    "writer.writerow(columns)\n",
    "c = 0\n",
    "with open('./yelp_dataset/yelp_academic_dataset_checkin.json') as data_file:\n",
    "    for line in data_file:\n",
    "        times = [0] * 24\n",
    "        c+=1\n",
    "        review = json.loads(line)\n",
    "        keys = review['checkin_info'].keys()\n",
    "        #print keys\n",
    "        total = 0\n",
    "        for key in keys:\n",
    "            hours = int(key.split('-')[0])\n",
    "            total +=  review['checkin_info'][key]\n",
    "            times[hours] += review['checkin_info'][key]\n",
    "        for i in range (len(times)):\n",
    "            times[i] =(\"{0:.2f}\".format(round(times[i]*1.0/total,2)))\n",
    "        \n",
    "\n",
    "        writer.writerow([review['business_id'], total, times[0], times[1], times[2], times[3], times[4], times[5],\n",
    "                         times[6], times[7], times[8], times[9], times[10], times[11], times[12], times[13], times[14],\n",
    "                          times[15], times[16],  times[17], times[18], times[19], times[20], times[21], times[22], times[23]]) \n",
    "                         \n",
    "\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
